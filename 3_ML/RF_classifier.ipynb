{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for training a random forest model to classify accident fatality\n",
    "\n",
    "#### First, train three basic RF models (using default settings) with the different training data (original, oversampled and undersampled)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data with no resampling\n",
    "X_train_orig = pd.read_csv('../0_data/X_train_orig_road_acc.csv')\n",
    "y_train_orig = pd.read_csv('../0_data/y_train_orig_road_acc.csv')\n",
    "\n",
    "# Oversampled training data\n",
    "X_train_oversamp = pd.read_csv('../0_data/X_train_oversamp_road_acc.csv')\n",
    "y_train_oversamp = pd.read_csv('../0_data/y_train_oversamp_road_acc.csv')\n",
    "\n",
    "# Undersampled training data\n",
    "X_train_undersamp = pd.read_csv('../0_data/X_train_undersamp_road_acc.csv')\n",
    "y_train_undersamp = pd.read_csv('../0_data/y_train_undersamp_road_acc.csv')\n",
    "\n",
    "\n",
    "# Validation data\n",
    "X_val = pd.read_csv('../0_data/X_val_road_acc.csv')\n",
    "y_val = pd.read_csv('../0_data/y_val_road_acc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF model trained on original (unbalanced) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF model (default values) trained on original (unbalanced) data\n",
      "Cross-validation scores for each fold: [0.98997223 0.9899275  0.98999442 0.98987172 0.99022867]\n",
      "Average cross-validation score: 0.989998906921973\n",
      "AUC Score: 0.585031640849742\n",
      "Validation Accuracy: 0.9900368542694734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     95168\n",
      "           1       0.00      0.00      0.00       886\n",
      "\n",
      "    accuracy                           0.99     96054\n",
      "   macro avg       0.50      0.50      0.50     96054\n",
      "weighted avg       0.98      0.99      0.99     96054\n",
      "\n",
      "Confusion Matrix:\n",
      "[[95097    71]\n",
      " [  886     0]]\n"
     ]
    }
   ],
   "source": [
    "rf_clf_orig = RandomForestClassifier(random_state = 33)\n",
    "\n",
    "# 5-fold cross-validation\n",
    "cv_scores_orig = cross_val_score(rf_clf_orig, X_train_orig, y_train_orig.values.ravel(), cv = 5)\n",
    "\n",
    "# Print the cross-validation scores for each fold and the mean CV score\n",
    "print(\"RF model (default values) trained on original (unbalanced) data\")\n",
    "print(\"Cross-validation scores for each fold:\", cv_scores_orig)\n",
    "print(\"Average cross-validation score:\", cv_scores_orig.mean())\n",
    "\n",
    "# Fit the model to original training data\n",
    "rf_clf_orig.fit(X_train_orig, y_train_orig.values.ravel())\n",
    "\n",
    "# Predicting probabilities on the validation set\n",
    "prob_predictions = rf_clf_orig.predict_proba(X_val)[:, 1]  # probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val.values.ravel(), prob_predictions)\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
    "class_predictions = rf_clf_orig.predict(X_val)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), class_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_val.values.ravel(), class_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val.values.ravel(), class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF model trained on oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF model (default values) trained on oversampled data\n",
      "Cross-validation scores for each fold: [0.95264124 0.97006918 0.9691685  0.96983838 0.97039568]\n",
      "Average cross-validation score: 0.9664225974102694\n",
      "AUC Score: 0.5879311408523987\n",
      "Validation Accuracy: 0.9551502279967519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98     95168\n",
      "           1       0.03      0.13      0.05       886\n",
      "\n",
      "    accuracy                           0.96     96054\n",
      "   macro avg       0.51      0.55      0.51     96054\n",
      "weighted avg       0.98      0.96      0.97     96054\n",
      "\n",
      "Confusion Matrix:\n",
      "[[91630  3538]\n",
      " [  770   116]]\n"
     ]
    }
   ],
   "source": [
    "rf_clf_oversamp = RandomForestClassifier(random_state = 33)\n",
    "\n",
    "# 5-fold cross-validation\n",
    "cv_scores_oversamp = cross_val_score(rf_clf_oversamp, X_train_oversamp, y_train_oversamp.values.ravel(), cv = 5)\n",
    "\n",
    "# Print the cross-validation scores for each fold\n",
    "print(\"RF model (default values) trained on oversampled data\")\n",
    "print(\"Cross-validation scores for each fold:\", cv_scores_oversamp)\n",
    "\n",
    "# Print the average cross-validation score\n",
    "print(\"Average cross-validation score:\", cv_scores_oversamp.mean())\n",
    "\n",
    "# Fit the model to original training data\n",
    "rf_clf_oversamp.fit(X_train_oversamp, y_train_oversamp.values.ravel())\n",
    "\n",
    "# Predicting probabilities on the validation set\n",
    "prob_predictions = rf_clf_oversamp.predict_proba(X_val)[:, 1]  # probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val.values.ravel(), prob_predictions)\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
    "class_predictions = rf_clf_oversamp.predict(X_val)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), class_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_val.values.ravel(), class_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val.values.ravel(), class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF model trained on undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF model (default values) trained on undersampled data\n",
      "Cross-validation scores for each fold: [0.6562123  0.67410984 0.65117683 0.67229934 0.65238383]\n",
      "Average cross-validation score: 0.6612364257931224\n",
      "AUC Score: 0.6840373696756388\n",
      "Validation Accuracy: 0.6697586774106232\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.67      0.80     95168\n",
      "           1       0.02      0.62      0.03       886\n",
      "\n",
      "    accuracy                           0.67     96054\n",
      "   macro avg       0.51      0.64      0.42     96054\n",
      "weighted avg       0.99      0.67      0.79     96054\n",
      "\n",
      "Confusion Matrix:\n",
      "[[63784 31384]\n",
      " [  337   549]]\n"
     ]
    }
   ],
   "source": [
    "rf_clf_undersamp = RandomForestClassifier(random_state = 33)\n",
    "\n",
    "# 5-fold cross-validation\n",
    "cv_scores_undersamp = cross_val_score(rf_clf_undersamp, X_train_undersamp, y_train_undersamp.values.ravel(), cv = 5)\n",
    "\n",
    "# Print the cross-validation scores for each fold\n",
    "print(\"RF model (default values) trained on undersampled data\")\n",
    "print(\"Cross-validation scores for each fold:\", cv_scores_undersamp)\n",
    "\n",
    "# Print the average cross-validation score\n",
    "print(\"Average cross-validation score:\", cv_scores_undersamp.mean())\n",
    "\n",
    "# Fit the model to original training data\n",
    "rf_clf_undersamp.fit(X_train_undersamp, y_train_undersamp.values.ravel())\n",
    "\n",
    "# Predicting probabilities on the validation set\n",
    "prob_predictions = rf_clf_undersamp.predict_proba(X_val)[:, 1]  # probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val.values.ravel(), prob_predictions)\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
    "class_predictions = rf_clf_undersamp.predict(X_val)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel() class_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_val.values.ravel(), class_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val.values.ravel(), class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the models yielded particularly good results, thus some parameter tuning will be needed. We will focus on oversampled and undersampled training data only for the parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning\n",
    "\n",
    "#### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the hyperparameter search on a subset of the whole dataset\n",
    "\n",
    "subset_size = 0.1 \n",
    "X_train_oversamp_subset = X_train_oversamp.sample(frac = subset_size, random_state = 33)\n",
    "y_train_oversamp_subset = y_train_oversamp.loc[X_train_oversamp_subset.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "# Define a parameter distribution to sample from\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [None, 10, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Initialize the base model\n",
    "rf_clf = RandomForestClassifier(random_state = 33)\n",
    "\n",
    "# Set up the RandomizedSearchCV object\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "    estimator = rf_clf,\n",
    "    param_distributions = param_distributions,\n",
    "    n_iter = 100,\n",
    "    cv = 5, \n",
    "    verbose = 2,\n",
    "    random_state = 33,\n",
    "    n_jobs = 12\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "rf_random_search.fit(X_train_oversamp_subset, y_train_oversamp_subset.values.ravel())\n",
    "\n",
    "# Get the best estimator\n",
    "best_rf_clf = rf_random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.6049742045811632\n",
      "Validation Accuracy: 0.9559726820330231\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98     95168\n",
      "           1       0.03      0.13      0.05       886\n",
      "\n",
      "    accuracy                           0.96     96054\n",
      "   macro avg       0.51      0.55      0.51     96054\n",
      "weighted avg       0.98      0.96      0.97     96054\n",
      "\n",
      "Confusion Matrix:\n",
      " [[91711  3457]\n",
      " [  772   114]]\n",
      "Best Hyperparameters:\n",
      " {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy', 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "# Fit the model with the best hyperparameters on the full oversampled training data\n",
    "best_rf_clf.fit(X_train_oversamp, y_train_oversamp.values.ravel())\n",
    "\n",
    "# Predicting probabilities on the validation set for AUC calculation\n",
    "prob_predictions = best_rf_clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val.values.ravel(), prob_predictions)\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
    "class_predictions = best_rf_clf.predict(X_val)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), class_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_val.values.ravel(), class_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val.values.ravel(), class_predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\\n\", rf_random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "AUC Score: 0.736727463354338\n",
      "Validation Accuracy: 0.7450288379453224\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.85     95168\n",
      "           1       0.02      0.61      0.04       886\n",
      "\n",
      "    accuracy                           0.75     96054\n",
      "   macro avg       0.51      0.68      0.45     96054\n",
      "weighted avg       0.99      0.75      0.85     96054\n",
      "\n",
      "Confusion Matrix:\n",
      " [[71021 24147]\n",
      " [  344   542]]\n",
      "Best Hyperparameters:\n",
      " {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'entropy', 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [None, 10, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Initialize the base model\n",
    "rf_clf = RandomForestClassifier(random_state = 33)\n",
    "\n",
    "# Set up the RandomizedSearchCV object\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "    estimator = rf_clf,\n",
    "    param_distributions = param_distributions,\n",
    "    n_iter = 100,\n",
    "    cv = 5, \n",
    "    verbose = 2,\n",
    "    random_state = 33,\n",
    "    n_jobs = 12\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "rf_random_search.fit(X_train_undersamp, y_train_undersamp.values.ravel())\n",
    "\n",
    "# Get the best estimator\n",
    "best_rf_clf = rf_random_search.best_estimator_\n",
    "\n",
    "# Fit the model with the best hyperparameters on the full oversampled training data\n",
    "best_rf_clf.fit(X_train_undersamp, y_train_undersamp.values.ravel())\n",
    "\n",
    "# Predicting probabilities on the validation set for AUC calculation\n",
    "prob_predictions = best_rf_clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val.values.ravel(), prob_predictions)\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
    "class_predictions = best_rf_clf.predict(X_val)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), class_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_val.values.ravel(), class_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val.values.ravel(), class_predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\\n\", rf_random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance of tunes models\n",
    "\n",
    "#### Oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.6049743231786089\n",
      "Validation Accuracy: 0.9559726820330231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98     95168\n",
      "           1       0.03      0.13      0.05       886\n",
      "\n",
      "    accuracy                           0.96     96054\n",
      "   macro avg       0.51      0.55      0.51     96054\n",
      "weighted avg       0.98      0.96      0.97     96054\n",
      "\n",
      "Confusion Matrix:\n",
      "[[91711  3457]\n",
      " [  772   114]]\n"
     ]
    }
   ],
   "source": [
    "# Retraining the model (in case not done at the same time as parameter tuning)\n",
    "\n",
    "best_rf_clf_over = RandomForestClassifier(n_estimators = 100,\n",
    "                                          criterion = 'entropy',\n",
    "                                          max_depth = None,\n",
    "                                          min_samples_split = 10,\n",
    "                                          min_samples_leaf = 1,\n",
    "                                          max_features = 'sqrt',\n",
    "                                          bootstrap = False,\n",
    "                                          n_jobs = 12,\n",
    "                                          random_state = 33)\n",
    "\n",
    "# Fit the model to oversampled training data\n",
    "best_rf_clf_over.fit(X_train_oversamp, y_train_oversamp.values.ravel())\n",
    "\n",
    "# Predicting probabilities on the validation set\n",
    "prob_predictions = best_rf_clf_over.predict_proba(X_val)[:, 1]  # probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val.values.ravel(), prob_predictions)\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
    "class_predictions = best_rf_clf_over.predict(X_val)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), class_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_val.values.ravel(), class_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val.values.ravel(), class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          feature  importance\n",
      "69                         speed_limit_bins_30-39    0.042290\n",
      "20                     junction_detail_roundabout    0.037156\n",
      "75                       time_of_day_evening_rush    0.035745\n",
      "0                              day_of_week_friday    0.034288\n",
      "6                           day_of_week_wednesday    0.033062\n",
      "..                                            ...         ...\n",
      "63  carriageway_hazards_pedestrian_in_carriageway    0.000102\n",
      "41          weather_conditions_snowing_high_winds    0.000094\n",
      "47     road_surface_conditions_oil_or_diesel_road    0.000031\n",
      "46               road_surface_conditions_mud_road    0.000008\n",
      "59                carriageway_hazards_dog_on_road    0.000007\n",
      "\n",
      "[79 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the encoder\n",
    "encoder = load('../0_data/encoder.joblib')\n",
    "\n",
    "# Get feature importances\n",
    "importances = best_rf_clf_over.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = encoder.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(feature_importances_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.736727463354338\n",
      "Validation Accuracy: 0.7450288379453224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.85     95168\n",
      "           1       0.02      0.61      0.04       886\n",
      "\n",
      "    accuracy                           0.75     96054\n",
      "   macro avg       0.51      0.68      0.45     96054\n",
      "weighted avg       0.99      0.75      0.85     96054\n",
      "\n",
      "Confusion Matrix:\n",
      "[[71021 24147]\n",
      " [  344   542]]\n"
     ]
    }
   ],
   "source": [
    "# Retraining the model (in case not done at the same time as parameter tuning)\n",
    "\n",
    "best_rf_clf_under = RandomForestClassifier(n_estimators = 100,\n",
    "                                          criterion = 'entropy',\n",
    "                                          max_depth = 10,\n",
    "                                          min_samples_split = 10,\n",
    "                                          min_samples_leaf = 4,\n",
    "                                          max_features = 'log2',\n",
    "                                          bootstrap = False,\n",
    "                                          n_jobs = 12,\n",
    "                                          random_state = 33)\n",
    "\n",
    "# Fit the model to oversampled training data\n",
    "best_rf_clf_under.fit(X_train_undersamp, y_train_undersamp.values.ravel())\n",
    "\n",
    "# Predicting probabilities on the validation set\n",
    "prob_predictions = best_rf_clf_under.predict_proba(X_val)[:, 1]  # probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val.values.ravel(), prob_predictions)\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
    "class_predictions = best_rf_clf_under.predict(X_val)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), class_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_val.values.ravel(), class_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val.values.ravel(), class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       feature  importance\n",
      "20                  junction_detail_roundabout    0.052845\n",
      "67                   urban_or_rural_area_urban    0.041857\n",
      "69                      speed_limit_bins_30-39    0.041367\n",
      "66                   urban_or_rural_area_rural    0.038626\n",
      "72                      speed_limit_bins_60-69    0.025161\n",
      "..                                         ...         ...\n",
      "65    carriageway_hazards_vehicle_load_on_road    0.000492\n",
      "44      road_surface_conditions_flood_over_3cm    0.000389\n",
      "41       weather_conditions_snowing_high_winds    0.000370\n",
      "47  road_surface_conditions_oil_or_diesel_road    0.000084\n",
      "59             carriageway_hazards_dog_on_road    0.000000\n",
      "\n",
      "[79 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the encoder\n",
    "encoder = load('../0_data/encoder.joblib')\n",
    "\n",
    "# Get feature importances\n",
    "importances = best_rf_clf_over.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = encoder.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(feature_importances_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
